{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14ea64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "976f978d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_yr</th>\n",
       "      <th>popularity_yr</th>\n",
       "      <th>mode</th>\n",
       "      <th>key_0_yr</th>\n",
       "      <th>key_1_yr</th>\n",
       "      <th>key_2_yr</th>\n",
       "      <th>key_3_yr</th>\n",
       "      <th>key_4_yr</th>\n",
       "      <th>key_5_yr</th>\n",
       "      <th>key_6_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>182347</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583424</td>\n",
       "      <td>35.272231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>206972</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-19.898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432251</td>\n",
       "      <td>3.672500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>314667</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-10.202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>179747</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>-6.590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>498560</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>-16.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>3.419500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172225</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>37000</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>-5.617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426566</td>\n",
       "      <td>27.599484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172226</th>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>501824</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-9.138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438681</td>\n",
       "      <td>29.107904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172227</th>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>161560</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>-17.372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490335</td>\n",
       "      <td>19.231500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172228</th>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>342827</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>-9.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>33.923039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172229</th>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>139514</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>-11.197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>33.923039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172230 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0           0.013100        0.2560       182347   0.895         0   \n",
       "1           0.980000        0.2770       206972   0.145         0   \n",
       "2           0.795000        0.6850       314667   0.483         0   \n",
       "3           0.656000        0.7880       179747   0.808         0   \n",
       "4           0.302000        0.0753       498560   0.150         0   \n",
       "...              ...           ...          ...     ...       ...   \n",
       "172225      0.000067        0.5670        37000   0.862         0   \n",
       "172226      0.000994        0.3960       501824   0.979         0   \n",
       "172227      0.864000        0.6380       161560   0.156         0   \n",
       "172228      0.029900        0.5330       342827   0.547         0   \n",
       "172229      0.141000        0.5260       139514   0.432         0   \n",
       "\n",
       "        instrumentalness  liveness  loudness  popularity  speechiness  ...  \\\n",
       "0               0.000106    0.0821    -4.860           0       0.0707  ...   \n",
       "1               0.879000    0.1110   -19.898           0       0.0845  ...   \n",
       "2               0.878000    0.1130   -10.202           0       0.0337  ...   \n",
       "3               0.000000    0.1540    -6.590           0       0.0395  ...   \n",
       "4               0.884000    0.1210   -16.705           0       0.0371  ...   \n",
       "...                  ...       ...       ...         ...          ...  ...   \n",
       "172225          0.875000    0.4810    -5.617           0       0.0670  ...   \n",
       "172226          0.609000    0.1360    -9.138           0       0.0878  ...   \n",
       "172227          0.000000    0.1830   -17.372           0       0.0741  ...   \n",
       "172228          0.011300    0.0723    -9.290           0       0.0326  ...   \n",
       "172229          0.000120    0.1340   -11.197           0       0.0306  ...   \n",
       "\n",
       "        valence_yr  popularity_yr  mode  key_0_yr  key_1_yr  key_2_yr  \\\n",
       "0         0.583424      35.272231     1         0         0         1   \n",
       "1         0.432251       3.672500     1         1         0         0   \n",
       "2         0.447291       7.707000     1         0         0         0   \n",
       "3         0.447291       7.707000     1         0         0         0   \n",
       "4         0.443625       3.419500     1         1         0         0   \n",
       "...            ...            ...   ...       ...       ...       ...   \n",
       "172225    0.426566      27.599484     1         0         0         0   \n",
       "172226    0.438681      29.107904     1         1         0         0   \n",
       "172227    0.490335      19.231500     1         1         0         0   \n",
       "172228    0.593672      33.923039     1         0         0         1   \n",
       "172229    0.593672      33.923039     1         0         0         1   \n",
       "\n",
       "        key_3_yr  key_4_yr  key_5_yr  key_6_yr  \n",
       "0              0         0         0         0  \n",
       "1              0         0         0         0  \n",
       "2              1         0         0         0  \n",
       "3              1         0         0         0  \n",
       "4              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "172225         0         1         0         0  \n",
       "172226         0         0         0         0  \n",
       "172227         0         0         0         0  \n",
       "172228         0         0         0         0  \n",
       "172229         0         0         0         0  \n",
       "\n",
       "[172230 rows x 72 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_21.csv')\n",
    "del df['id']\n",
    "\n",
    "mean_popularity = 50\n",
    "df[\"popularity\"] = [ 1 if i >= mean_popularity else 0 for i in df.popularity ]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4492d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['popularity'])]\n",
    "y = pd.cut(x=df[\"popularity\"], bins=[-1,42,100], labels=[0,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce675da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=31).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea27cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "264 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 100.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 20.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 60.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 40.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 80.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan  1. nan nan nan  1. nan  1. nan nan nan nan nan nan  1.\n",
      " nan nan nan nan nan nan  1. nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan  1. nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan  1. nan nan nan nan nan nan  1. nan nan nan\n",
      " nan nan nan nan  1. nan nan nan nan nan nan nan nan nan nan nan  1. nan\n",
      " nan nan  1. nan nan  1. nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=31),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [20.0, 40.0, 60.0, 80.0,\n",
       "                                                      100.0, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=31),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [20.0, 40.0, 60.0, 80.0,\n",
       "                                                      100.0, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=31)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=31)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=31),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [20.0, 40.0, 60.0, 80.0,\n",
       "                                                      100.0, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)] # Number of Decisions Trees in the forest\n",
    "max_features = ['auto', 'sqrt']                                                 # Max features used to split at each node\n",
    "max_depth = np.linspace(20,100,5).tolist()                                      # Max depth of each tree\n",
    "max_depth.append(None) \n",
    "bootstrap = [True, False]\n",
    "min_samples_split = [2, 5, 10]                                                  # Minimum samples required to split at a node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "\n",
    "# Parameter Grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=31)\n",
    "random_rfc = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "                                random_state=42, n_jobs = -1)\n",
    "random_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef99017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff947b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf=RandomForestClassifier(n_estimators=400, max_depth=20, max_features='sqrt', criterion='gini', min_samples_leaf=4,\n",
    "                               min_samples_split=2, bootstrap=False, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf=rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d40ed768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mClassification Report\n",
      "\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34446\n",
      "\n",
      "    accuracy                           1.00     34446\n",
      "   macro avg       1.00      1.00      1.00     34446\n",
      "weighted avg       1.00      1.00      1.00     34446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mClassification Report')\n",
    "print('\\033[0m')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1ed5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dba3d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_21.csv')\n",
    "del df['id']\n",
    "mean_popularity = 50\n",
    "df[\"popularity\"] = [ 1 if i >= mean_popularity else 0 for i in df.popularity ]\n",
    "df[\"popularity\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c72fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df.drop(['popularity'], axis=1)\n",
    "y = df['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebda709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20a6dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl = XGBClassifier(loss='binary_crossentropy', max_iter=1000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "049e0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [50, 100, 200], \n",
    "          'learning_rate': [0.01, 0.1, 0.2], \n",
    "          'objective': ['binary:logistic'], \n",
    "         'max_depth': [3, 5, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4e085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = GridSearchCV(xgb_cl, params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bf8f78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:17:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:18:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:19:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"loss\", \"max_iter\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_iter=1000, max_leaves=None,\n",
       "                                     min_child_weight=None, missing=nan,\n",
       "                                     monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7], &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_iter=1000, max_leaves=None,\n",
       "                                     min_child_weight=None, missing=nan,\n",
       "                                     monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7], &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None,\n",
       "              loss=&#x27;binary_crossentropy&#x27;, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_iter=1000, max_leaves=None, min_child_weight=None,\n",
       "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
       "              n_estimators=None, n_jobs=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None,\n",
       "              loss=&#x27;binary_crossentropy&#x27;, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_iter=1000, max_leaves=None, min_child_weight=None,\n",
       "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
       "              n_estimators=None, n_jobs=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_iter=1000, max_leaves=None,\n",
       "                                     min_child_weight=None, missing=nan,\n",
       "                                     monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7], 'n_estimators': [50, 100, 200],\n",
       "                         'objective': ['binary:logistic']})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa04ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb96db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mClassification Report\n",
      "\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     28684\n",
      "           1       0.85      0.66      0.74      5762\n",
      "\n",
      "    accuracy                           0.92     34446\n",
      "   macro avg       0.89      0.82      0.85     34446\n",
      "weighted avg       0.92      0.92      0.92     34446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mClassification Report')\n",
    "print('\\033[0m')\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9738759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48c6ef18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>tempo_yr</th>\n",
       "      <th>valence_yr</th>\n",
       "      <th>popularity_yr</th>\n",
       "      <th>key_0_yr</th>\n",
       "      <th>key_1_yr</th>\n",
       "      <th>key_2_yr</th>\n",
       "      <th>key_3_yr</th>\n",
       "      <th>key_4_yr</th>\n",
       "      <th>key_5_yr</th>\n",
       "      <th>key_6_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>182347</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-4.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>...</td>\n",
       "      <td>120.209319</td>\n",
       "      <td>0.583424</td>\n",
       "      <td>35.272231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>206972</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-19.898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>...</td>\n",
       "      <td>110.008113</td>\n",
       "      <td>0.432251</td>\n",
       "      <td>3.672500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>314667</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-10.202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>...</td>\n",
       "      <td>108.561912</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>179747</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>-6.590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>...</td>\n",
       "      <td>108.561912</td>\n",
       "      <td>0.447291</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>498560</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>-16.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>...</td>\n",
       "      <td>109.569882</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>3.419500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172225</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>37000</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>-5.617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>...</td>\n",
       "      <td>123.644288</td>\n",
       "      <td>0.426566</td>\n",
       "      <td>27.599484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172226</th>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>501824</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-9.138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>...</td>\n",
       "      <td>124.621497</td>\n",
       "      <td>0.438681</td>\n",
       "      <td>29.107904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172227</th>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>161560</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>-17.372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>...</td>\n",
       "      <td>112.511724</td>\n",
       "      <td>0.490335</td>\n",
       "      <td>19.231500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172228</th>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>342827</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>-9.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>...</td>\n",
       "      <td>119.346342</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>33.923039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172229</th>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>139514</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>-11.197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>...</td>\n",
       "      <td>119.346342</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>33.923039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172230 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0           0.013100        0.2560       182347   0.895         0   \n",
       "1           0.980000        0.2770       206972   0.145         0   \n",
       "2           0.795000        0.6850       314667   0.483         0   \n",
       "3           0.656000        0.7880       179747   0.808         0   \n",
       "4           0.302000        0.0753       498560   0.150         0   \n",
       "...              ...           ...          ...     ...       ...   \n",
       "172225      0.000067        0.5670        37000   0.862         0   \n",
       "172226      0.000994        0.3960       501824   0.979         0   \n",
       "172227      0.864000        0.6380       161560   0.156         0   \n",
       "172228      0.029900        0.5330       342827   0.547         0   \n",
       "172229      0.141000        0.5260       139514   0.432         0   \n",
       "\n",
       "        instrumentalness  liveness  loudness  popularity  speechiness  ...  \\\n",
       "0               0.000106    0.0821    -4.860           0       0.0707  ...   \n",
       "1               0.879000    0.1110   -19.898           0       0.0845  ...   \n",
       "2               0.878000    0.1130   -10.202           0       0.0337  ...   \n",
       "3               0.000000    0.1540    -6.590           0       0.0395  ...   \n",
       "4               0.884000    0.1210   -16.705           0       0.0371  ...   \n",
       "...                  ...       ...       ...         ...          ...  ...   \n",
       "172225          0.875000    0.4810    -5.617           0       0.0670  ...   \n",
       "172226          0.609000    0.1360    -9.138           0       0.0878  ...   \n",
       "172227          0.000000    0.1830   -17.372           0       0.0741  ...   \n",
       "172228          0.011300    0.0723    -9.290           0       0.0326  ...   \n",
       "172229          0.000120    0.1340   -11.197           0       0.0306  ...   \n",
       "\n",
       "          tempo_yr  valence_yr  popularity_yr  key_0_yr  key_1_yr  key_2_yr  \\\n",
       "0       120.209319    0.583424      35.272231         0         0         1   \n",
       "1       110.008113    0.432251       3.672500         1         0         0   \n",
       "2       108.561912    0.447291       7.707000         0         0         0   \n",
       "3       108.561912    0.447291       7.707000         0         0         0   \n",
       "4       109.569882    0.443625       3.419500         1         0         0   \n",
       "...            ...         ...            ...       ...       ...       ...   \n",
       "172225  123.644288    0.426566      27.599484         0         0         0   \n",
       "172226  124.621497    0.438681      29.107904         1         0         0   \n",
       "172227  112.511724    0.490335      19.231500         1         0         0   \n",
       "172228  119.346342    0.593672      33.923039         0         0         1   \n",
       "172229  119.346342    0.593672      33.923039         0         0         1   \n",
       "\n",
       "        key_3_yr  key_4_yr  key_5_yr  key_6_yr  \n",
       "0              0         0         0         0  \n",
       "1              0         0         0         0  \n",
       "2              1         0         0         0  \n",
       "3              1         0         0         0  \n",
       "4              0         0         0         0  \n",
       "...          ...       ...       ...       ...  \n",
       "172225         0         1         0         0  \n",
       "172226         0         0         0         0  \n",
       "172227         0         0         0         0  \n",
       "172228         0         0         0         0  \n",
       "172229         0         0         0         0  \n",
       "\n",
       "[172230 rows x 71 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_21.csv')\n",
    "del df['mode']\n",
    "del df['id']\n",
    "\n",
    "mean_popularity = 50\n",
    "df[\"popularity\"] = [ 1 if i >= mean_popularity else 0 for i in df.popularity ]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52e11411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'popularity', 'speechiness',\n",
       "       'tempo', 'valence', 'year', 'key_0', 'key_1', 'key_2', 'key_3', 'key_4',\n",
       "       'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10', 'key_11',\n",
       "       'minor', 'major', 'acousticness_ar', 'danceability_ar',\n",
       "       'duration_ms_ar', 'energy_ar', 'instrumentalness_ar', 'liveness_ar',\n",
       "       'loudness_ar', 'speechiness_ar', 'tempo_ar', 'valence_ar',\n",
       "       'popularity_ar', 'count', 'key_0_ar', 'key_1_ar', 'key_2_ar',\n",
       "       'key_3_ar', 'key_4_ar', 'key_5_ar', 'key_6_ar', 'key_7_ar', 'key_8_ar',\n",
       "       'key_9_ar', 'key_10_ar', 'key_11_ar', 'minor_ar', 'major_ar',\n",
       "       'acousticness_yr', 'danceability_yr', 'duration_ms_yr', 'energy_yr',\n",
       "       'instrumentalness_yr', 'liveness_yr', 'loudness_yr', 'speechiness_yr',\n",
       "       'tempo_yr', 'valence_yr', 'popularity_yr', 'key_0_yr', 'key_1_yr',\n",
       "       'key_2_yr', 'key_3_yr', 'key_4_yr', 'key_5_yr', 'key_6_yr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a71be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"popularity\"].values\n",
    "X = df.drop([\"popularity\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e109dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = StandardScaler()\n",
    "X_normalized = input_scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.30, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4c1a32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172230, 70)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "855badfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40ce40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Perceptron()\n",
    "\n",
    "clf = Perceptron(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43ad774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijayramaraju/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.19865465, 0.18026304, 0.159971  , 0.11696804, 0.1235199 ,\n",
       "        0.13862514, 0.13611853, 0.12722456, 0.1124984 , 0.12370396,\n",
       "        0.15319049, 0.16830492, 0.16978884, 0.19447792, 0.21553481,\n",
       "        0.24345052]),\n",
       " 'std_fit_time': array([0.03349447, 0.00428581, 0.0127449 , 0.00356805, 0.00608516,\n",
       "        0.01044202, 0.00076759, 0.00137246, 0.01422966, 0.00875115,\n",
       "        0.01584351, 0.00853205, 0.05135798, 0.07754004, 0.07022703,\n",
       "        0.05154145]),\n",
       " 'mean_score_time': array([0.01065743, 0.00695634, 0.0098561 , 0.00811386, 0.00652349,\n",
       "        0.00828958, 0.00996745, 0.00697196, 0.00971961, 0.01004207,\n",
       "        0.01175439, 0.00917947, 0.00854456, 0.01195753, 0.01693916,\n",
       "        0.0155915 ]),\n",
       " 'std_score_time': array([0.00208437, 0.0003655 , 0.00038397, 0.00335383, 0.00174034,\n",
       "        0.00172544, 0.00541747, 0.00224197, 0.00211143, 0.00206506,\n",
       "        0.00055063, 0.00203168, 0.00384748, 0.00726259, 0.00634503,\n",
       "        0.0097307 ]),\n",
       " 'param_eta0': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[10, 100, 1000, 10000, 10, 100, 1000, 10000, 10, 100,\n",
       "                    1000, 10000, 10, 100, 1000, 10000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'eta0': 0.0001, 'max_iter': 10},\n",
       "  {'eta0': 0.0001, 'max_iter': 100},\n",
       "  {'eta0': 0.0001, 'max_iter': 1000},\n",
       "  {'eta0': 0.0001, 'max_iter': 10000},\n",
       "  {'eta0': 0.001, 'max_iter': 10},\n",
       "  {'eta0': 0.001, 'max_iter': 100},\n",
       "  {'eta0': 0.001, 'max_iter': 1000},\n",
       "  {'eta0': 0.001, 'max_iter': 10000},\n",
       "  {'eta0': 0.01, 'max_iter': 10},\n",
       "  {'eta0': 0.01, 'max_iter': 100},\n",
       "  {'eta0': 0.01, 'max_iter': 1000},\n",
       "  {'eta0': 0.01, 'max_iter': 10000},\n",
       "  {'eta0': 0.1, 'max_iter': 10},\n",
       "  {'eta0': 0.1, 'max_iter': 100},\n",
       "  {'eta0': 0.1, 'max_iter': 1000},\n",
       "  {'eta0': 0.1, 'max_iter': 10000}],\n",
       " 'split0_test_score': array([0.87568948, 0.87568948, 0.87568948, 0.87568948, 0.87568948,\n",
       "        0.87568948, 0.87568948, 0.87568948, 0.87568948, 0.87568948,\n",
       "        0.87568948, 0.87568948, 0.86628346, 0.86635604, 0.86635604,\n",
       "        0.86635604]),\n",
       " 'split1_test_score': array([0.87333798, 0.87333798, 0.87333798, 0.87333798, 0.87333798,\n",
       "        0.87333798, 0.87333798, 0.87333798, 0.87333798, 0.87333798,\n",
       "        0.87333798, 0.87333798, 0.87333798, 0.87333798, 0.87333798,\n",
       "        0.87333798]),\n",
       " 'mean_test_score': array([0.87451373, 0.87451373, 0.87451373, 0.87451373, 0.87451373,\n",
       "        0.87451373, 0.87451373, 0.87451373, 0.87451373, 0.87451373,\n",
       "        0.87451373, 0.87451373, 0.86981072, 0.86984701, 0.86984701,\n",
       "        0.86984701]),\n",
       " 'std_test_score': array([0.00117575, 0.00117575, 0.00117575, 0.00117575, 0.00117575,\n",
       "        0.00117575, 0.00117575, 0.00117575, 0.00117575, 0.00117575,\n",
       "        0.00117575, 0.00117575, 0.00352726, 0.00349097, 0.00349097,\n",
       "        0.00349097]),\n",
       " 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 16, 13, 13, 13],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01 , 0.1 ]}\n",
    "\n",
    "clf1 = GridSearchCV(model, {\n",
    "    'eta0' : [ 0.0001, 0.001, 0.01, 0.1], 'max_iter' : [10, 100, 1000, 10000]}, cv = 2, return_train_score = False)\n",
    "\n",
    "clf1.fit(X_train , y_train)\n",
    "clf1.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b242489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.198655</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 10}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.180263</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 100}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159971</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 1000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116968</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.0001, 'max_iter': 10000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123520</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 10}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138625</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 100}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.136119</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 1000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.127225</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.001, 'max_iter': 10000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.112498</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 10}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.123704</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 100}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.153190</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 1000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.168305</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.01, 'max_iter': 10000}</td>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.169789</td>\n",
       "      <td>0.051358</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 10}</td>\n",
       "      <td>0.866283</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.869811</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.194478</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 100}</td>\n",
       "      <td>0.866356</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.869847</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.215535</td>\n",
       "      <td>0.070227</td>\n",
       "      <td>0.016939</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>0.866356</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.869847</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.243451</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'eta0': 0.1, 'max_iter': 10000}</td>\n",
       "      <td>0.866356</td>\n",
       "      <td>0.873338</td>\n",
       "      <td>0.869847</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_eta0  \\\n",
       "0        0.198655      0.033494         0.010657        0.002084     0.0001   \n",
       "1        0.180263      0.004286         0.006956        0.000365     0.0001   \n",
       "2        0.159971      0.012745         0.009856        0.000384     0.0001   \n",
       "3        0.116968      0.003568         0.008114        0.003354     0.0001   \n",
       "4        0.123520      0.006085         0.006523        0.001740      0.001   \n",
       "5        0.138625      0.010442         0.008290        0.001725      0.001   \n",
       "6        0.136119      0.000768         0.009967        0.005417      0.001   \n",
       "7        0.127225      0.001372         0.006972        0.002242      0.001   \n",
       "8        0.112498      0.014230         0.009720        0.002111       0.01   \n",
       "9        0.123704      0.008751         0.010042        0.002065       0.01   \n",
       "10       0.153190      0.015844         0.011754        0.000551       0.01   \n",
       "11       0.168305      0.008532         0.009179        0.002032       0.01   \n",
       "12       0.169789      0.051358         0.008545        0.003847        0.1   \n",
       "13       0.194478      0.077540         0.011958        0.007263        0.1   \n",
       "14       0.215535      0.070227         0.016939        0.006345        0.1   \n",
       "15       0.243451      0.051541         0.015592        0.009731        0.1   \n",
       "\n",
       "   param_max_iter                               params  split0_test_score  \\\n",
       "0              10     {'eta0': 0.0001, 'max_iter': 10}           0.875689   \n",
       "1             100    {'eta0': 0.0001, 'max_iter': 100}           0.875689   \n",
       "2            1000   {'eta0': 0.0001, 'max_iter': 1000}           0.875689   \n",
       "3           10000  {'eta0': 0.0001, 'max_iter': 10000}           0.875689   \n",
       "4              10      {'eta0': 0.001, 'max_iter': 10}           0.875689   \n",
       "5             100     {'eta0': 0.001, 'max_iter': 100}           0.875689   \n",
       "6            1000    {'eta0': 0.001, 'max_iter': 1000}           0.875689   \n",
       "7           10000   {'eta0': 0.001, 'max_iter': 10000}           0.875689   \n",
       "8              10       {'eta0': 0.01, 'max_iter': 10}           0.875689   \n",
       "9             100      {'eta0': 0.01, 'max_iter': 100}           0.875689   \n",
       "10           1000     {'eta0': 0.01, 'max_iter': 1000}           0.875689   \n",
       "11          10000    {'eta0': 0.01, 'max_iter': 10000}           0.875689   \n",
       "12             10        {'eta0': 0.1, 'max_iter': 10}           0.866283   \n",
       "13            100       {'eta0': 0.1, 'max_iter': 100}           0.866356   \n",
       "14           1000      {'eta0': 0.1, 'max_iter': 1000}           0.866356   \n",
       "15          10000     {'eta0': 0.1, 'max_iter': 10000}           0.866356   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.873338         0.874514        0.001176                1  \n",
       "1            0.873338         0.874514        0.001176                1  \n",
       "2            0.873338         0.874514        0.001176                1  \n",
       "3            0.873338         0.874514        0.001176                1  \n",
       "4            0.873338         0.874514        0.001176                1  \n",
       "5            0.873338         0.874514        0.001176                1  \n",
       "6            0.873338         0.874514        0.001176                1  \n",
       "7            0.873338         0.874514        0.001176                1  \n",
       "8            0.873338         0.874514        0.001176                1  \n",
       "9            0.873338         0.874514        0.001176                1  \n",
       "10           0.873338         0.874514        0.001176                1  \n",
       "11           0.873338         0.874514        0.001176                1  \n",
       "12           0.873338         0.869811        0.003527               16  \n",
       "13           0.873338         0.869847        0.003491               13  \n",
       "14           0.873338         0.869847        0.003491               13  \n",
       "15           0.873338         0.869847        0.003491               13  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best at \n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(clf1.cv_results_)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d025451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best : {'eta0': 0.01, 'max_iter': 10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f406bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(random_state=0, max_iter=10000, eta0 = 0.01).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f97fd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8754717528885793"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47288c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e944092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764152586657377"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97e28f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     28768\n",
      "           1       0.63      0.62      0.62      5678\n",
      "\n",
      "    accuracy                           0.88     34446\n",
      "   macro avg       0.78      0.77      0.77     34446\n",
      "weighted avg       0.88      0.88      0.88     34446\n",
      "\n",
      "Classification report\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Classification report\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f169ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
